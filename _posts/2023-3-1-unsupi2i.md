---
title: "[Paper] Unsupervised Image-to-Image Translation: A Review"
layout: post
post-image: "/assets/posts/unsupi2i/thumb.png"
description: MDPI sensors 2022
tags:
- I2I
- unsupervised learning
- computer vision
---

### Remaining Problems in unsupervised I2I
1. Complex translations : some tasks need heavy modification
2. Effectiveness of training is needed
3. Data Scarcity


Traditional I2I translation required paired dataset. i.e., not random data from each domain but 1-1 paired dataset were needed. However, in real world, this kind of dataset is extremely limited. <br>

Hence, later I2I translation has some variations such as style-content disentanglement. (content : want to preserve, style : wnat to change) e.g. MUNIT, UNIT. These map a single image into two latent spaces and work on  non-paired dataset. 


---

This concept was also encountered while surveying pathology-related literature and is well illustrated in a figure found in the upper right corner. UNIT's latent sharing approach is often used in unsupervised anomaly detection in the field of imaging.

![method1](/assets/posts/unsupi2i/ad.png){: width="100%"}


Structurally, UNIT works by taking an image from domain A and passing it through a style encoder and a content encoder to obtain two latent vectors. These vectors are then fed into a decoder for reconstruction during training. During inference, the content encoder of domain A is used in combination with the style encoder of domain B. This encoded data is then passed through the decoder of domain B to perform the generative model's function.


### Commonly adopted losses
1. Adversarial loss
2. Cycle consistency 
3. Identity loss ( to preserve relevant features e.g. borders)

### Commonly used datasets
1. Face datasets - Animal Face, CelevA, FlickrFace
2. Segmentation Datasets - ADE20K, CityScapes
3. Outdoor dataset - Yosemities, Foggy Driving
4. Strong change on style or shapes : Deep Fashion, Oxford-102 flowers, Birds(kaggle), INIT (for autonomous driving)
5. Classical Dataset : Apple 2 Orange, Colored MNIST, ArtWork

### Ways to guide the translation models
1. Disentanglement Learning
2. Contrastive Learning

### Applications 
1. Complex translations : 2D to 3D translation
2. Progressive learning : TUIGAN, coarse to fine method, diffusion based architecture, UNIT-DDPM
3. Data issues : few-shot or one shot
4. Limited data