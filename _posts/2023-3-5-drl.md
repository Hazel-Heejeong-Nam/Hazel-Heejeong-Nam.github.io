---
title: "[Paper] Disentangled Representation Learning"
layout: post
post-image: "/assets/posts/drl/thumb.png"
description: 
tags:
- disentangling
- representation learning
- computer vision
---

**Disentanglement Learning** learns **factor of variants**.

#### Benefit
1. Invariant with external semantics
2. Not reflecting biased semantic
3. Learn robust semantic


![fig](/assets/posts/drl/fig1.png){: width='100%'}

 One observed data is mapped to several feature spaces, where each feature space has its own semantic.


### Baseline Methods
1. Generative Models
2. Causal Inference : Robustly disentangled causal mechanisms - Validating deep representations for interventional robustness
3. Group theory : Towards a definition of disentangled representations


The definition of DRL has evolved over time, and two common perspectives on its definition are as follows:

1. **Latent Vector Independence**: Each latent vector in the representation should be sensitive to variations in its specific factor while being invariant to changes in other factors. This implies that each dimension of the latent space should capture a distinct, independent piece of information about the data.

2. **Assumption of Independence**: While the major definition of DRL assumes that generative factors are independent, some models have moved away from this assumption, acknowledging that in real-world data, factors of variation are often interdependent.


### VAE based disentangling
The use of vanilla Variational Autoencoders (VAEs) as a base for DRL can be attributed to their objective function, specifically the Evidence Lower Bound (ELBO). The KL divergence term in ELBO encourages the latent space to have independent dimensions, making $q(z|x)$ similar to $p(z)$.

Furthermore, in the case of beta-VAEs, increasing the beta value improves disentangling performance but degrades reconstruction performance, indicating a trade-off. The increased beta value enhances dimension-wise independence at the cost of reduced information retention.

### Variations of VAE based method
Variants of VAEs have been used for disentangling purposes, typically :

1. Following an unsupervised approach 
2. Incorporating* extra regularizers or total correlation.

### Other methods
- Causal VAE based methods
- GAN based methods
- Hierarchy based methods
- Pretrained Generator as Prior
- Distilling Unknown factors with weak supervision
- Incorporating Supervisions with Few labels

### Categories:

1. **Dimension-wise**: Where each dimension of the generative factor represents a different semantic meaning. This is mostly tested on synthetic and simple datasets.

2. **Vector-wise**: Different vectors represent different types of semantic meanings and are tested in real-world scenarios.

### Metric
Z-min Variance, Z-max Variance, Mutual Information Gap (MIC), SAP score, DCI, UNIBOUND, UC, and GC.

### Applications
DRL is applied in various domains, including image and video processing, NLP, multimodal applications, recommendation systems, and graph representation learning.

### Design scheme

1. **Appropriate Representation Structure According to a Specific Task**: 
   - Dimension-wise: Using GANs or VAEs as a backbone and designing extra losses tailored to the task, or employing models like InfoSwap to discard task-irrelevant features.
   - Vector-wise: Presetting vectors (e.g., motion encoder, appearance encoder) or using clustering-based methods to separate the original representation into different vectors.

2. **Designing Corresponding Loss Functions**: 

