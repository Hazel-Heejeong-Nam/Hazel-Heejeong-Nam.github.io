---
title: "[Paper] Agree to Disagree: Diversity through Disagreement for Better Transferability"
layout: post
post-image: "/assets/posts/dbat/thumb.png"
description: ICLR 2023 
tags:
    Simplicity bias
    Representation Learning
    Computer vision
---

### Motivation:

The motivation behind DBAT is to eliminate simplicity bias and enable the learning of robust and transferable features.

### Method

The method involves training an ensemble of models on both in-distribution and out-distribution data.

### Details

Assuming there are n heads, the models are trained as follows:
    For in-distribution data, the models aim to reach an agreement.
    For out-of-distribution (OOD) data, the models aim to disagree.

![Image](/assets/posts/dbat/1.png){: width='100%'}

*Upper image: This provides an intuitive explanation of the approach.*

### Expectation

The expectation is to address the issue of simplicity bias and ensure diversity in features, leading to better generalization.

### Implementation

![Image](/assets/posts/dbat/2.png){: width='80%'}

**Pseudo Code**

```python

For the i-th model:
    Evaluate all previous models (up to the i-th model).
    For each epoch:
        Calculate ERM loss using cross-entropy loss (pred(x), y).

        If DBAT loss is v1:
            For models up to (i-1)-th model:
                1. Perform inference with x_tilde using the (i-1)-th model.
                2. Apply softmax.
                3. Take the index with the maximum value and store it in p_1_s.
            * Perform inference with x_tilde using the i-th model-> get indices of p_1_s
            * Calculate AG (Agreement)

        If DBAT loss is v2:
            1. Perform inference with x_tilde using the i-th model.
            2. Apply softmax.
            3. Store the index with the maximum value in p_2_s.
            * p_s_1 =[torch.softmax(m_(x_tilde), dim=1) for m_ in ensemble[:m_idx]] 
            * p_1_1_s = [p_1[torch.arange(len(p_1)), max_idx] for p_1 in p_1_s]
            * Calculate AG based on p_1_1_s.

        The average of AG is used as the loss, and the models are updated accordingly.
```

---
**Diversify and Disambiguate: Learning From Underspecified Data**
This paper also deals with similar problem, and also accepted at ICLR 2023.

* motivation : address issue of source and taret shift

* setting :  labeled source data, unlabeled target data (similar to D-BAT)

* method : Generate several *learners* first, then choose best one.

![Image](/assets/posts/dbat/3.png){: width='100%'}

They train each pair of heads to produce predictions that are close to being statistically independent.

**how? disagreement**
(When distinguishing between camels and cows, the red classifier likely relies on the color of the animal, while the blue classifier may focus on the background color. Both classifiers are expected to achieve high accuracy in classification. In this scenario, a cow in the desert would likely be the most disagreed datapoint.)

â€‹

#### How to choose better learner?
1. active querying

2. random querying

3. disambiguation on source data